{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e96abfb",
   "metadata": {},
   "source": [
    "\n",
    "Accounting for imbalance in evaluation metrics for classification \n",
    "=================================================================\n",
    "\n",
    "Suppose we have a population of subjects with features `X` that can hopefully\n",
    "serve as indicators of a binary class `y` (known ground truth). Additionally,\n",
    "suppose the class prevalence (the number of samples in the positive class\n",
    "divided by the total number of samples) is very low.\n",
    "\n",
    "To fix ideas, let's use a medical analogy and think about diabetes. We only\n",
    "use two features -age and blood sugar level-, to keep the example as simple as\n",
    "possible. We use `make_classification` to simulate the distribution of the\n",
    "disease and to ensure **the data-generating process is always the same**. We\n",
    "set the `weights=[0.99, 0.01]` to obtain a prevalence of around 1% which,\n",
    "according to [The World\n",
    "Bank](https://data.worldbank.org/indicator/SH.STA.DIAB.ZS?most_recent_value_desc=false),\n",
    "is the case for the country with the lowest diabetes prevalence in 2022\n",
    "(Benin).\n",
    "\n",
    "In practice, the ideas presented here can be applied in settings where the\n",
    "data available to learn and evaluate a classifier has nearly balanced classes,\n",
    "such as a case-control study, while the target application, i.e. the general\n",
    "population, has very low prevalence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782caccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "common_params = {\n",
    "    \"n_samples\": 10_000,\n",
    "    \"n_features\": 2,\n",
    "    \"n_informative\": 2,\n",
    "    \"n_redundant\": 0,\n",
    "    \"n_classes\": 2, # binary classification\n",
    "    \"shift\": [4, 6],\n",
    "    \"scale\": [10, 25],\n",
    "    \"random_state\": 0,\n",
    "}\n",
    "X, y = make_classification(**common_params, weights=[0.99, 0.01])\n",
    "prevalence = y.mean()\n",
    "print(f\"Percentage of people carrying the disease: {100*prevalence:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfb3e1a",
   "metadata": {},
   "source": [
    "A simple model is trained to diagnose if a person is likely to have diabetes.\n",
    "To estimate the generalization performance of such model, we do a train-test\n",
    "split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf725eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=0)\n",
    "\n",
    "estimator = DecisionTreeClassifier(max_depth=2, random_state=0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e172eaea",
   "metadata": {},
   "source": [
    "The most widely used summary metric is arguably accuracy. Its main advantage\n",
    "is a natural interpretation: the proportion of correctly classified samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deae9b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_pred = estimator.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy on the test set: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039aa5c8",
   "metadata": {},
   "source": [
    "However, it is misleading when the data is imbalanced. Our model performs\n",
    "as well as a trivial majority classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f719fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy = DummyClassifier(strategy=\"most_frequent\").fit(X_train, y_train)\n",
    "y_dummy = estimator.predict(X_test)\n",
    "accuracy_dummy = metrics.accuracy_score(y_test, y_dummy)\n",
    "print(f\"Accuracy if Diabetes did not exist: {accuracy_dummy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991da63b",
   "metadata": {},
   "source": [
    "Some of the other metrics are better at describing the flaws of our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edf2d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity = metrics.recall_score(y_test, y_pred)\n",
    "specificity = metrics.recall_score(y_test, y_pred, pos_label=0)\n",
    "balanced_acc = metrics.balanced_accuracy_score(y_test, y_pred)\n",
    "matthews = metrics.matthews_corrcoef(y_test, y_pred)\n",
    "PPV = metrics.precision_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Sensitivity on the test set: {sensitivity:.2f}\")\n",
    "print(f\"Specificity on the test set: {specificity:.2f}\")\n",
    "print(f\"Balanced accuracy on the test set: {balanced_acc:.2f}\")\n",
    "print(f\"Matthews correlation coeff on the test set: {matthews:.2f}\")\n",
    "print()\n",
    "print(f\"Probability to have the disease given a positive test: {100*PPV:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8075c87",
   "metadata": {},
   "source": [
    "Our classifier is not informative enough on the general population. The PPV\n",
    "and NPV give the information of interest: P(D+ | T+) and P(D− | T−). However,\n",
    "they are not intrinsic to the medical test (in other words the trained ML\n",
    "model) but also depend on the prevalence and thus on the target population.\n",
    "\n",
    "The class likelihood ratios (LR±) depend only on sensitivity and specificity\n",
    "of the classifier, and not on the prevalence of the study population. For the\n",
    "moment it suffice to recall that LR± is defined as\n",
    "\n",
    "    LR± = P(D± | T+) / P(D± | T−)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c5f76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_LR, neg_LR = metrics.class_likelihood_ratios(y_test, y_pred)\n",
    "print(f\"LR+ on the test set: {pos_LR:.3f}\") # higher is better\n",
    "print(f\"LR- on the test set: {neg_LR:.3f}\") #  lower is better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027b6406",
   "metadata": {},
   "source": [
    "<div class=\"admonition note alert alert-info\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Caution</p>\n",
    "<p class=\"last\">Please notice that if you want to use the\n",
    "`metrics.class_likelihood_ratios` as of today, you require the 1.2.dev0\n",
    "version of scikit-learn. This metric will be implemented in version 1.2.0.\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "Extrapolating between populations\n",
    "---------------------------------\n",
    "\n",
    "The prevalence can be variable (for instance the prevalence of an infectious\n",
    "disease will be variable across time) and a given classifier may be intended\n",
    "to be applied in various situations.\n",
    "\n",
    "According to the World Bank, the diabetes prevalence in the French Polynesia\n",
    "in 2022 is above 25%. Let's now evaluate our previously trained model on a\n",
    "**different population** with such prevalence and **the same data-generating\n",
    "process**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989d3742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "X, y = make_classification(**common_params, weights=[0.75, 0.25])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=0)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "disp = DecisionBoundaryDisplay.from_estimator(\n",
    "    estimator,\n",
    "    X_test,\n",
    "    response_method=\"predict\",\n",
    "    alpha=0.5,\n",
    "    xlabel=\"age (years)\",\n",
    "    ylabel=\"blood sugar level (mg/dL)\",\n",
    "    ax=ax,\n",
    ")\n",
    "scatter = disp.ax_.scatter(X_test[:, 0], X_test[:, 1], c=y_test, edgecolor=\"k\")\n",
    "disp.ax_.set_title(f\"Diabetes test with prevalence = {y.mean():.2f}\")\n",
    "_ = disp.ax_.legend(*scatter.legend_elements())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6643d072",
   "metadata": {},
   "source": [
    "We compute the same metrics using a test set with the new prevalence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79af0a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = estimator.predict(X_test)\n",
    "prevalence = y.mean()\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "sensitivity = metrics.recall_score(y_test, y_pred)\n",
    "specificity = metrics.recall_score(y_test, y_pred, pos_label=0)\n",
    "balanced_acc = metrics.balanced_accuracy_score(y_test, y_pred)\n",
    "matthews = metrics.matthews_corrcoef(y_test, y_pred)\n",
    "PPV = metrics.precision_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy on the test set: {accuracy:.2f}\")\n",
    "print(f\"Sensitivity on the test set: {sensitivity:.2f}\")\n",
    "print(f\"Specificity on the test set: {specificity:.2f}\")\n",
    "print(f\"Balanced accuracy on the test set: {balanced_acc:.2f}\")\n",
    "print(f\"Matthews correlation coeff on the test set: {matthews:.2f}\")\n",
    "print()\n",
    "print(f\"Probability to have the disease given a positive test: {100*PPV:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92054e35",
   "metadata": {},
   "source": [
    "The same model seems to perform better on this new dataset. Notice in\n",
    "particular that the probability to have the disease given a positive test\n",
    "increased. The same blood sugar test is less predictive in Benin than in\n",
    "the French Polynesia!\n",
    "\n",
    "If we really want to score the test and not the dataset, we need a metric that\n",
    "does not depend on the prevalence of the study population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91b5bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_LR, neg_LR = metrics.class_likelihood_ratios(y_test, y_pred)\n",
    "\n",
    "print(f\"LR+ on the test set: {pos_LR:.3f}\")\n",
    "print(f\"LR- on the test set: {neg_LR:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e81a313",
   "metadata": {},
   "source": [
    "Despite some variations due to residual dataset dependence, the class\n",
    "likelihood ratios are mathematically invariant with respect to prevalence. See\n",
    "[this example from the User\n",
    "Guide](https://scikit-learn.org/dev/auto_examples/model_selection/plot_likelihood_ratios.html#invariance-with-respect-to-prevalence)\n",
    "for a demo regarding such property.\n",
    "\n",
    "Pre-test vs. post-test odds\n",
    "---------------------------\n",
    "\n",
    "Both class likelihood ratios are interpretable in terms of odds:\n",
    "\n",
    "    post-test odds = Likelihood ratio * pre-test odds\n",
    "\n",
    "The interpretation of LR+ in this case reads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdec6fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The post-test odds that the condition is truly present given a positive \"\n",
    "     f\"test result are: {pos_LR:.3f} times larger than the pre-test odds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea971dda",
   "metadata": {},
   "source": [
    "We found that diagnosis tool is useful: the post-test odds are larger than the\n",
    "pre-test odds. We now choose the pre-test probability to be the prevalence of\n",
    "the disease in the held-out testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25be1d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretest_odds = y_test.mean() / (1 - y_test.mean())\n",
    "posttest_odds = pretest_odds * pos_LR\n",
    "\n",
    "print(f\"Observed pre-test odds: {pretest_odds:.3f}\")\n",
    "print(f\"Estimated post-test odds using LR+: {posttest_odds:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25564775",
   "metadata": {},
   "source": [
    "The post-test probability is the probability of an individual to truly have\n",
    "the condition given a positive test result, i.e. the number of true positives\n",
    "divided by the total number of samples. In real life applications this is\n",
    "unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8293808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "posttest_prob = posttest_odds / (1 + posttest_odds)\n",
    "\n",
    "print(f\"Estimated post-test probability using LR+: {posttest_prob:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce68e27",
   "metadata": {},
   "source": [
    "We can verify that if we had had access to the true labels, we would have\n",
    "obatined the same probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a597438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "posttest_prob = y_test[y_pred == 1].mean()\n",
    "\n",
    "print(f\"Observed post-test probability: {posttest_prob:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad444e86",
   "metadata": {},
   "source": [
    "Conclusion: If a Benin salesperson was to sell the model to the French Polynesia\n",
    "by showing them the 59.84% probability to have the disease given a positive test,\n",
    "the French Polynesia would have never bought it, even though it would be quite\n",
    "predictive for their own population. The right thing to report are the LR±.\n",
    "\n",
    "Can you imagine what would happen if the model is trained on nearly balanced classes\n",
    "and then extrapolated to other scenarios?"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
